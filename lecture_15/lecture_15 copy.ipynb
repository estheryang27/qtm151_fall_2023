{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> Lecture 15 - Practicing Chaining </span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> I. Import Libraries and Data </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = \"Esther Yang\"\n",
    "ID = 2487073\n",
    "print(Name)\n",
    "print(ID)\n",
    "\n",
    "print(\"I will abide by Emory's code of conduct\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results  = pd.read_csv(\"data_raw/results.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> II. Review Dataset Operations </span>\n",
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "See attached file for a refresher on syntax\n",
    "\n",
    "```[] ``` $\\qquad \\qquad \\qquad \\quad$: Extracting columns <br>\n",
    "```.query() ``` $\\qquad \\qquad $: Subsetting rows <br>\n",
    "```.recode() ``` $ \\qquad \\quad \\ \\ $: Replacing values <br>\n",
    "```.groupby().agg() ```: Aggregate statistics by subgroup <br>\n",
    "```.rename() ``` $\\qquad \\quad \\ \\ $: Change name of columns\n",
    "\n",
    "Full list:\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "https://www.w3schools.com/python/pandas/pandas_ref_dataframe.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkblue\"> III. Quiz Structure </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "(a) Replace the values of a column\n",
    "\n",
    "- Obtain unique string values of a column\n",
    "- Use the \".replace()\" command\n",
    "\n",
    "Hint: See Lecture 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can reference subattributes of columns in \".query()\"\n",
    "# The pd.unique() function extracts unique values from a list\n",
    "subset = circuits.query(\"alt.str.isnumeric() == False\")\n",
    "list_unique = pd.unique(subset[\"alt\"])\n",
    "print(list_unique)\n",
    "\n",
    "\n",
    "# Replace certain values\n",
    "# \"list_old\" encodes values we want to change\n",
    "# \"list_new\" encodes the values that will \"replace\" the old\n",
    "list_old = ['\\\\N','-7']\n",
    "list_new = [1, -7]\n",
    "\n",
    "# This command replaces the values of the \"alt\" column\n",
    "circuits[\"alt\"] = circuits[\"alt\"].replace(list_old, list_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(b) Recode a numeric column\n",
    "\n",
    "- Use the \"pd.cut()\" command to create <br>\n",
    "a new column based on an interval.\n",
    "- See Lecture 12 for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode values based on an interval\n",
    "\n",
    "bins_x = [0,2500, 5000]\n",
    "labels_x = [\"Between 0 and 2500\",\n",
    "            \"Between 2500 and 5000\"]\n",
    "\n",
    "circuits[\"bins_alt\"] = pd.cut(circuits[\"alt_numeric\"],\n",
    "                              bins = bins_x,\n",
    "                              right = True,\n",
    "                              labels = labels_x)\n",
    "\n",
    "# Note: if we set bins_x = [float(\"-inf\"),2500, float(\"inf\")]\n",
    "#       then intervals are \"Less than or equal to 2500\" and \"Above 2500\"\n",
    "#       float(\"inf\") and float(\"-inf\") represent infinity and negative infinity\n",
    "#       The \"right\" command indicates that the right interval is\n",
    "#       \"less than or equal to\" or just \"less than\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(c) Aggregate and query\n",
    "\n",
    "- Use a combniation of the following commands <br>\n",
    "to produce a new dataset <br>\n",
    "``` .query() ``` <br>\n",
    "``` .groupby().agg() ``` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering + Grouping + Aggregating: .query().groupby().agg()\n",
    "\n",
    "# The following gets a subset of the data using .query()\n",
    "# In this case we subset the data before computing aggregate statistics\n",
    "# Note: \"filtering\" is often the word used to obtain a subset\n",
    "\n",
    "teamrace_agg = (results.query(\"raceId >= 500\")\n",
    "                       .groupby([\"raceId\",\"constructorId\"])\n",
    "                        .agg(mean_points = ('points','mean'),\n",
    "                             sd_points =   ('points','std'),\n",
    "                             min_points =  ('points','min'),\n",
    "                             max_points =  ('points','max'),\n",
    "                             count_obs   = ('points',len)))\n",
    "\n",
    "teamrace_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(d) Aggregate and sort\n",
    "\n",
    "- Use a combniation of the following commands <br>\n",
    "to produce a new dataset <br>\n",
    "``` .groupby().agg() ``` <br>\n",
    "``` .sort_values() ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a chain \".sort_values(...,ascending = False)\" \n",
    "\n",
    "df_aggConstrcId_pos = (sprint_results.groupby(\"constructorId\")\n",
    "                                   .agg(mean_position=('position','mean'),\n",
    "                                        sd_position=('position','std')))\n",
    "\n",
    "df_aggConstrcId_pos = df_aggConstrcId_pos.sort_values(by='mean_position', ascending=True) #smallest to largest\n",
    "\n",
    "display(df_aggConstrcId_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(e) Rename column\n",
    "\n",
    "- Create a dictionary\n",
    "- Rename one or more columns in a dataset <br>\n",
    "using the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first define the dictionary\n",
    "# Change the pipe \".rename(...)\" to rename the columns\n",
    "# Dictionaries can flexibly accommodate single values or list after \":\"\n",
    "\n",
    "dict_rename_circuits = {\"name\": \"circuit_name\"}\n",
    "circuits = circuits_raw.rename(columns = dict_rename_circuits)\n",
    "\n",
    "# Rename columns using dictionaries\n",
    "# {\"old_name\": \"new_name\"}\n",
    "circuits_raw.rename(columns={'name':'circuit_name'})\n",
    "\n",
    "# This is an example of a pandas data frame created from a dictionary\n",
    "# This example illustrates the basic syntax of a dictionary\n",
    "\n",
    "car_dictionary = {\"car_model\": [\"Ferrari\",\"Tesla\",\"BMW\",\"Something\"],\n",
    "                  \"year\": [\"2018\",\"2023\",\"2022\", \"1993\"]}\n",
    "\n",
    "pd.DataFrame(car_dictionary)\n",
    "\n",
    "# Check that \".rename()\" worked\n",
    "# Extract the column names of the \"raw\" and \"clean\" data\n",
    "\n",
    "print(\"Old List:\")\n",
    "print(circuits_raw.columns.values)\n",
    "print(\"\")\n",
    "print(\"New List:\")\n",
    "print(circuits.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(f) Merge dataset\n",
    "\n",
    "- Use \"pd.merge\" to combine two datasets: <br>\n",
    "a primary and secondary\n",
    "- Only merge a subset of the columns of the <br>\n",
    "secondary dataset\n",
    "- Use \"display\" to show a the merged dataset,  <br>\n",
    "extracting a subset of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"pd.merge()\" command combines the information from both datasets\n",
    "# The first argument is the \"primary\" datasets\n",
    "# The second argument is the \"secondary\" dataset (much include the \"on\" column)\n",
    "# The \"on\" is the common variable that is used for merging\n",
    "# how = \"left\" tells Python that the left dataset is the primary one\n",
    "\n",
    "races_merge = pd.merge(races_raw[['raceId', 'year', 'circuitId']],\n",
    "                       circuits[[\"circuitId\",\"circuit_name\", \"location\"]],\n",
    "                       on = \"circuitId\", #common column\n",
    "                       how = \"left\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45fc1f684f6f416f40889115beff3ddf69879b64cf4bfee48cb72a61e9d15d1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
